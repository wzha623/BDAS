{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, count, col, log, avg\n",
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Spark to read csv file\n",
    "SuicideStats = spark.read.csv(\"data/who_suicide_statistics.csv\",inferSchema=True,header=True)\n",
    "\n",
    "HDIStats = spark.read.csv(\"data/Human Development Index.csv\",inferSchema=True, header=True, nullValue=\"..\")\n",
    "\n",
    "WDIStats = spark.read.csv(\"data/World_Development_Indicators.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Manipulation\n",
    "\n",
    "#Selecting Items\n",
    "SuicideStats.createOrReplaceTempView('suicideStats')\n",
    "SuicideStats = spark.sql(\"SELECT * FROM suicideStats WHERE population >= 0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove HDI Rank from HDIStats\n",
    "HDIStats = HDIStats.drop(\"HDI Rank\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "#remove misssing values from WHO Suicide Statistics\n",
    "SuicideStats = SuicideStats.na.drop(subset=\"suicides_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean value of each country\n",
    "from pyspark.sql.functions import mean\n",
    "\n",
    "HDIStatsMean = HDIStats.na.fill(0)\n",
    "HDIStatsMean = HDIStatsMean.select(col('Country'), (sum(col(x) for x in HDIStats.columns[1:]) / len(HDIStats.columns)-1).alias(\"mean\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDIStats = HDIStats.alias('a')\\\n",
    "    .join(HDIStatsMean.alias('b'),col('b.Country') == col('a.Country'))\\\n",
    "    .select([when(col('a.'+xx).isNull(), col('b.mean')).otherwise(col('a.'+xx)).alias(xx) for xx in HDIStats.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanig WDIStats\n",
    "#replace missing value with the mean value of this country\n",
    "\n",
    "def fill_with_mean(df, exclude=set()): \n",
    "    stats = df.agg(*(\n",
    "        avg(c).alias(c) for c in df.columns if c not in exclude\n",
    "    ))\n",
    "    return df.na.fill(stats.first().asDict())\n",
    "\n",
    "WDIStats = fill_with_mean(WDIStats, [\"Country Name\", \"Year\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove extreme and outliers\n",
    "from pyspark.sql import DataFrameStatFunctions\n",
    "\n",
    "bounds = {\n",
    "    c: dict(\n",
    "        zip([\"q1\", \"q3\"], SuicideStats.approxQuantile(c, [0.25, 0.75], 0))\n",
    "    )\n",
    "    for c in SuicideStats.columns if c in [\"suicides_no\", \"population\"]\n",
    "}\n",
    "\n",
    "for c in bounds:\n",
    "    iqr = bounds[c]['q3'] - bounds[c]['q1']\n",
    "    bounds[c]['lower'] = bounds[c]['q1'] - (iqr * 1.5)\n",
    "    bounds[c]['upper'] = bounds[c]['q3'] + (iqr * 1.5)\n",
    "\n",
    "SuicideStats = SuicideStats.select(\n",
    "    \"*\",\n",
    "    *[\n",
    "        when(\n",
    "            col(c).between(bounds[c]['lower'], bounds[c]['upper']),\n",
    "            0\n",
    "        ).otherwise(1).alias(c+\"_out\") \n",
    "        for c in SuicideStats.columns  if c in [\"suicides_no\", \"population\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "SuicideStats.createOrReplaceTempView('SuicideStats')\n",
    "SuicideStats = spark.sql(\"SELECT country, year, sex, age, suicides_no, population FROM SuicideStats WHERE suicides_no_out = 0 and population_out=0 \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the Data\n",
    "#add new feature suicidePer100k to SuicideStats\n",
    "\n",
    "SuicideStats = SuicideStats.withColumn(\"SuicidePer100k\", col(\"suicides_no\")/col(\"population\")*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transport HDI score \n",
    "#HDIStats.columns\n",
    "from pyspark.sql.functions import array, col, explode, struct, lit\n",
    "\n",
    "cols, dtypes = zip(*((c, t) for (c, t) in HDIStats.dtypes if c not in ['Country']))\n",
    "kvs = explode(array([\n",
    "      struct(lit(c).alias(\"Year\"), col(c).alias(\"HDIScore\")) for c in cols\n",
    "    ])).alias(\"kvs\")\n",
    "    \n",
    "HDIStats = HDIStats.select(['Country'] + [kvs]).select(['Country'] + [\"kvs.Year\", \"kvs.HDIScore\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrate Data Sources\n",
    "\n",
    "#rename columns\n",
    "SuicideStats = SuicideStats.withColumnRenamed(\"country\",\"Country\")\\\n",
    "    .withColumnRenamed(\"year\",\"Year\")\\\n",
    "    .withColumnRenamed(\"sex\",\"Sex\")\\\n",
    "    .withColumnRenamed(\"age\",\"Age\")\\\n",
    "    .withColumnRenamed(\"suicides_no\",\"SuicidesNo\")\\\n",
    "    .withColumnRenamed(\"population\",\"Population\")\n",
    "\n",
    "WDIStats = WDIStats.withColumnRenamed(\"Country Name\",\"Country\")\\\n",
    "    .withColumnRenamed(\"Employment to population ratio\",\"EmploymentToPopulationRatio\")\\\n",
    "    .withColumnRenamed(\"GDP per capita\",\"GDPPerCapita\")\\\n",
    "    .withColumnRenamed(\"Gini index\",\"GiniIndex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+-----------+----------+----------+------------------+--------+---------------------------+-------------+------------+-----------------+\n",
      "|Country|Year| Sex|        Age|SuicidesNo|Population|    SuicidePer100k|HDIScore|EmploymentToPopulationRatio|          GDP|GDPPerCapita|        GiniIndex|\n",
      "+-------+----+----+-----------+----------+----------+------------------+--------+---------------------------+-------------+------------+-----------------+\n",
      "|Albania|1992|male|  75+ years|         0|     23900|               0.0|   0.608|                54.30599976|4.038036613E9| 1243.605824|38.62148387096775|\n",
      "|Albania|1992|male|55-74 years|         5|    159500| 3.134796238244514|   0.608|                54.30599976|4.038036613E9| 1243.605824|38.62148387096775|\n",
      "|Albania|1992|male| 5-14 years|         0|    362900|               0.0|   0.608|                54.30599976|4.038036613E9| 1243.605824|38.62148387096775|\n",
      "|Albania|1992|male|35-54 years|        12|    343800|3.4904013961605584|   0.608|                54.30599976|4.038036613E9| 1243.605824|38.62148387096775|\n",
      "|Albania|1992|male|25-34 years|         7|    245500|2.8513238289205702|   0.608|                54.30599976|4.038036613E9| 1243.605824|38.62148387096775|\n",
      "|Albania|1992|male|15-24 years|         9|    263700|3.4129692832764507|   0.608|                54.30599976|4.038036613E9| 1243.605824|38.62148387096775|\n",
      "+-------+----+----+-----------+----------+----------+------------------+--------+---------------------------+-------------+------------+-----------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#merge data to a single data frame\n",
    "datasource = SuicideStats\\\n",
    "    .join(HDIStats, (SuicideStats.Country == HDIStats.Country) & (SuicideStats.Year == HDIStats.Year))\\\n",
    "    .join(WDIStats, (SuicideStats.Country == WDIStats.Country) & (SuicideStats.Year == WDIStats.Year))\\\n",
    "    .select([SuicideStats.Country, SuicideStats.Year, SuicideStats.Sex, SuicideStats.Age, SuicideStats.SuicidesNo,\n",
    "             SuicideStats.Population, SuicideStats.SuicidePer100k, HDIStats.HDIScore,\n",
    "             WDIStats.EmploymentToPopulationRatio, WDIStats.GDP, WDIStats.GDPPerCapita, WDIStats.GiniIndex])\n",
    "\n",
    "datasource.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop some columns\n",
    "datasource = datasource.drop('SuicidesNo')\\\n",
    "    .drop('Population')\\\n",
    "    .drop('Year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = datasource.withColumn(\"LogGDPPerCapita\", log(\"GDPPerCapita\")).withColumn(\"LogGDP\", log(\"GDP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Country: string, Sex: string, Age: string, SuicidePer100k: double, HDIScore: double, EmploymentToPopulationRatio: double, GDP: double, GDPPerCapita: double, GiniIndex: double, LogGDPPerCapita: double, LogGDP: double]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasource.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of dataset is:  (17665, 11)\n",
      "The size of training data is:  (12335, 11)\n",
      "The size of test data is:  (5330, 11)\n"
     ]
    }
   ],
   "source": [
    "#Train and Test Split\n",
    "# Split the data\n",
    "(train, test) = datasource.randomSplit([0.7, 0.3], seed =722)\n",
    "print(\"The size of dataset is: \",(datasource.count(), len(datasource.columns)))\n",
    "print(\"The size of training data is: \", (train.count(), len(train.columns)))\n",
    "print(\"The size of test data is: \", (test.count(), len(test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casts all columns to a numeric type\n",
    "sexIndexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
    "ageIndexer = StringIndexer(inputCol=\"Age\", outputCol=\"AgeIndex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresCols = ['HDIScore', 'EmploymentToPopulationRatio', 'LogGDPPerCapita', 'LogGDP', 'GiniIndex', 'SexIndex', 'AgeIndex']\n",
    "featureAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")\n",
    "featureIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"indexedFeatures\", maxCategories=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the \"features\" column and learns to predict \"SuicidePer100k\"\n",
    "gbt = GBTRegressor(featuresCol=\"indexedFeatures\",labelCol=\"SuicidePer100k\", maxIter=5, maxDepth=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline(stages=[sexIndexer, ageIndexer, featureAssembler, featureIndexer, gbt])\n",
    "\n",
    "#pipelineModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = pipelineModel.transform(test)\n",
    "#display(predictions.select(\"SuicidePer100k\", \"prediction\", *featuresCols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluator = RegressionEvaluator(\n",
    "#    labelCol=\"SuicidePer100k\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "#rmse = evaluator.evaluate(predictions)\n",
    "#print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "  .addGrid(gbt.maxDepth, [2, 15])\\\n",
    "  .addGrid(gbt.maxIter, [2, 15])\\\n",
    "  .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n",
    "\n",
    "cv = CrossValidator(estimator=gbt, evaluator=evaluator, estimatorParamMaps=paramGrid, numFolds=3)\n",
    "\n",
    "pipeline = Pipeline(stages=[sexIndexer, ageIndexer, featureAssembler, featureIndexer, cv])\n",
    "\n",
    "pipelineModel = pipeline.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
