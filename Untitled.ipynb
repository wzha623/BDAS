{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()\n",
    "\n",
    "from pyspark.sql.types import (StructField,StringType,IntegerType,StructType)\n",
    "from pyspark.sql.functions import mean, avg\n",
    "from pyspark.sql import DataFrameStatFunctions\n",
    "from pyspark.sql.functions import array, col, explode, struct, lit\n",
    "from pyspark.sql.functions import when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Spark to read csv file\n",
    "SuicideStats = spark.read.csv(\"data/who_suicide_statistics.csv\",inferSchema=True,header=True)\n",
    "SuicideStats.createOrReplaceTempView('suicideStats')\n",
    "SuicideStats = spark.sql(\"SELECT * FROM suicideStats WHERE population >= 0\")\n",
    "\n",
    "SuicideStats = SuicideStats.na.drop(subset=\"suicides_no\")\n",
    "bounds = {\n",
    "    c: dict(\n",
    "        zip([\"q1\", \"q3\"], SuicideStats.approxQuantile(c, [0.25, 0.75], 0))\n",
    "    )\n",
    "    for c in SuicideStats.columns if c in [\"suicides_no\", \"population\"]\n",
    "}\n",
    "\n",
    "for c in bounds:\n",
    "    iqr = bounds[c]['q3'] - bounds[c]['q1']\n",
    "    bounds[c]['lower'] = bounds[c]['q1'] - (iqr * 1.5)\n",
    "    bounds[c]['upper'] = bounds[c]['q3'] + (iqr * 1.5)\n",
    "\n",
    "SuicideStats = SuicideStats.select(\n",
    "    \"*\",\n",
    "    *[\n",
    "        when(\n",
    "            col(c).between(bounds[c]['lower'], bounds[c]['upper']),\n",
    "            0\n",
    "        ).otherwise(1).alias(c+\"_out\") \n",
    "        for c in SuicideStats.columns  if c in [\"suicides_no\", \"population\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "SuicideStats.createOrReplaceTempView('SuicideStats')\n",
    "SuicideStats = spark.sql(\"SELECT country, year, sex, age, suicides_no, population FROM SuicideStats WHERE suicides_no_out = 0 and population_out=0 \")\n",
    "\n",
    "SuicideStats = SuicideStats.withColumn(\"SuicidePer100k\", col(\"suicides_no\")/col(\"population\")*100000)\n",
    "\n",
    "SuicideStats = SuicideStats.withColumnRenamed(\"country\",\"Country\")\\\n",
    "    .withColumnRenamed(\"year\",\"Year\")\\\n",
    "    .withColumnRenamed(\"sex\",\"Sex\")\\\n",
    "    .withColumnRenamed(\"age\",\"Age\")\\\n",
    "    .withColumnRenamed(\"suicides_no\",\"SuicidesNo\")\\\n",
    "    .withColumnRenamed(\"population\",\"Population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[country: string, year: int, sex: string, age: string, suicides_no: int, population: int]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SuicideStats1 = spark.read.csv(\"data/who_suicide_statistics.csv\",inferSchema=True,header=True)\n",
    "SuicideStats1.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SuicideStats2 = spark.read.csv(\"data/who_suicide_statistics.csv\",inferSchema=True,header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 664 objects.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "collected = gc.collect()\n",
    "print (\"Garbage collector: collected %d objects.\" % collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country', 'year', 'sex', 'age', 'suicides_no', 'population']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SuicideStats2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country', 'year', 'sex', 'age', 'suicides_no', 'population']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SuicideStats1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDIStats = spark.read.csv(\"data/Human Development Index.csv\",inferSchema=True, header=True, nullValue=\"..\")\n",
    "HDIStats = HDIStats.drop(\"HDI Rank\")\n",
    "\n",
    "HDIStatsMean = HDIStats.na.fill(0)\n",
    "HDIStatsMean = HDIStatsMean.select(col('Country'), (sum(col(x) for x in HDIStats.columns[1:]) / len(HDIStats.columns)-1).alias(\"mean\"))\n",
    "HDIStats = HDIStats.alias('a')\\\n",
    "    .join(HDIStatsMean.alias('b'),col('b.Country') == col('a.Country'))\\\n",
    "    .select([when(col('a.'+xx).isNull(), col('b.mean')).otherwise(col('a.'+xx)).alias(xx) for xx in HDIStats.columns])\n",
    "\n",
    "cols, dtypes = zip(*((c, t) for (c, t) in HDIStats.dtypes if c not in ['Country']))\n",
    "kvs = explode(array([\n",
    "      struct(lit(c).alias(\"Year\"), col(c).alias(\"HDIScore\")) for c in cols\n",
    "    ])).alias(\"kvs\")\n",
    "    \n",
    "HDIStats = HDIStats.select(['Country'] + [kvs]).select(['Country'] + [\"kvs.Year\", \"kvs.HDIScore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WDIStats\n",
    "WDIStats = spark.read.csv(\"data/World_Development_Indicators.csv\",inferSchema=True,header=True)\n",
    "\n",
    "def fill_with_mean(df, exclude=set()): \n",
    "    stats = df.agg(*(\n",
    "        avg(c).alias(c) for c in df.columns if c not in exclude\n",
    "    ))\n",
    "    return df.na.fill(stats.first().asDict())\n",
    "\n",
    "WDIStats = fill_with_mean(WDIStats, [\"Country Name\", \"Year\"])\n",
    "\n",
    "WDIStats = WDIStats.withColumnRenamed(\"Country Name\",\"Country\")\\\n",
    "    .withColumnRenamed(\"Employment to population ratio\",\"EmploymentToPopulationRatio\")\\\n",
    "    .withColumnRenamed(\"GDP per capita\",\"GDPPerCapita\")\\\n",
    "    .withColumnRenamed(\"Gini index\",\"GiniIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17665, 12)\n"
     ]
    }
   ],
   "source": [
    "#Integrate Data Sources\n",
    "datasource = SuicideStats\\\n",
    "    .join(HDIStats, (SuicideStats.Country == HDIStats.Country) & (SuicideStats.Year == HDIStats.Year))\\\n",
    "    .join(WDIStats, (SuicideStats.Country == WDIStats.Country) & (SuicideStats.Year == WDIStats.Year))\\\n",
    "    .select([SuicideStats.Country, SuicideStats.Year, SuicideStats.Sex, SuicideStats.Age, SuicideStats.SuicidesNo,\n",
    "             SuicideStats.Population, SuicideStats.SuicidePer100k, HDIStats.HDIScore,\n",
    "             WDIStats.EmploymentToPopulationRatio, WDIStats.GDP, WDIStats.GDPPerCapita, WDIStats.GiniIndex])\n",
    "\n",
    "print((datasource.count(), len(datasource.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import log\n",
    "\n",
    "datasource = datasource.withColumn(\"LogGDPPerCapita\", log(\"GDPPerCapita\")).withColumn(\"LogGDP\", log(\"GDP\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of dataset is:  (17665, 14)\n",
      "The size of training data is:  (12385, 14)\n",
      "The size of test data is:  (5280, 14)\n"
     ]
    }
   ],
   "source": [
    "(train, test) = datasource.randomSplit([0.7, 0.3])\n",
    "print(\"The size of dataset is: \",(datasource.count(), len(datasource.columns)))\n",
    "print(\"The size of training data is: \", (train.count(), len(train.columns)))\n",
    "print(\"The size of test data is: \", (test.count(), len(test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexIndexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
    "ageIndexer = StringIndexer(inputCol=\"Age\", outputCol=\"AgeIndex\")\n",
    "\n",
    "featuresCols = ['HDIScore', 'EmploymentToPopulationRatio', 'LogGDP', 'LogGDPPerCapita', 'GiniIndex', 'SexIndex', 'AgeIndex']\n",
    "featureAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")\n",
    "featureIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"indexedFeatures\", maxCategories=4)\n",
    "\n",
    "\n",
    "gbt = GBTRegressor(featuresCol=\"indexedFeatures\",labelCol=\"SuicidePer100k\", maxIter=5, maxDepth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[sexIndexer, ageIndexer, featureAssembler, featureIndexer, gbt])\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+-----------+----------+----------+------------------+--------+---------------------------+-------------+------------+-----------------+------------------+------------------+--------+--------+--------------------+--------------------+------------------+\n",
      "|Country|Year|   Sex|        Age|SuicidesNo|Population|    SuicidePer100k|HDIScore|EmploymentToPopulationRatio|          GDP|GDPPerCapita|        GiniIndex|   LogGDPPerCapita|            LogGDP|SexIndex|AgeIndex|         rawFeatures|     indexedFeatures|        prediction|\n",
      "+-------+----+------+-----------+----------+----------+------------------+--------+---------------------------+-------------+------------+-----------------+------------------+------------------+--------+--------+--------------------+--------------------+------------------+\n",
      "|Albania|1992|female|15-24 years|         7|    292400|2.3939808481532148|   0.608|                54.30599976|4.038036613E9| 1243.605824|38.62148387096775|7.1257703613515035| 22.11902442390838|     0.0|     3.0|[0.608,54.3059997...|[0.608,54.3059997...|4.4091448541770815|\n",
      "|Albania|1992|female|  75+ years|         0|     38700|               0.0|   0.608|                54.30599976|4.038036613E9| 1243.605824|38.62148387096775|7.1257703613515035| 22.11902442390838|     0.0|     0.0|[0.608,54.3059997...|[0.608,54.3059997...| 3.063193233597685|\n",
      "|Albania|1992|  male|55-74 years|         5|    159500| 3.134796238244514|   0.608|                54.30599976|4.038036613E9| 1243.605824|38.62148387096775|7.1257703613515035| 22.11902442390838|     1.0|     4.0|[0.608,54.3059997...|[0.608,54.3059997...|30.073824996003896|\n",
      "|Albania|1993|female|55-74 years|         2|    169500|1.1799410029498525|   0.611|                53.53699875|4.424049157E9| 1370.826071|38.62148387096775| 7.223168808640724|22.210321212542325|     0.0|     4.0|[0.611,53.5369987...|[0.611,53.5369987...|3.5657123338374537|\n",
      "|Albania|1993|  male|35-54 years|        10|    350300|2.8546959748786755|   0.611|                53.53699875|4.424049157E9| 1370.826071|38.62148387096775| 7.223168808640724|22.210321212542325|     1.0|     5.0|[0.611,53.5369987...|[0.611,53.5369987...|29.361306022066092|\n",
      "|Albania|1993|  male|55-74 years|         7|    165000| 4.242424242424242|   0.611|                53.53699875|4.424049157E9| 1370.826071|38.62148387096775| 7.223168808640724|22.210321212542325|     1.0|     4.0|[0.611,53.5369987...|[0.611,53.5369987...|30.073824996003896|\n",
      "+-------+----+------+-----------+----------+----------+------------------+--------+---------------------------+-------------+------------+-----------------+------------------+------------------+--------+--------+--------------------+--------------------+------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[SuicidePer100k: double, prediction: double, HDIScore: double, EmploymentToPopulationRatio: double, LogGDP: double, LogGDPPerCapita: double, GiniIndex: double, SexIndex: double, AgeIndex: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions.select(\"SuicidePer100k\", \"prediction\", *featuresCols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 13.948\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"SuicidePer100k\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(7, {0: 0.0634, 1: 0.1193, 2: 0.2314, 3: 0.2252, 4: 0.0549, 5: 0.1289, 6: 0.1769})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[-1].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtModel = model.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressionModel (uid=dtr_f86df48770e1) of depth 3 with 15 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_95f2037f4212) of depth 3 with 15 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_25f2e0a02028) of depth 3 with 15 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_1cacccfebfa3) of depth 3 with 15 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_175045b303e9) of depth 3 with 15 nodes]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtModel.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Define a grid of hyperparameters to test:\n",
    "#  - maxDepth: max depth of each decision tree in the GBT ensemble\n",
    "#  - maxIter: iterations, i.e., number of trees in each GBT ensemble\n",
    "# In this example notebook, we keep these values small.  In practice, to get the highest accuracy, you would likely want to try deeper trees (10 or higher) and more trees in the ensemble (>100)\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "  .addGrid(gbt.maxDepth, [2, 3])\\\n",
    "  .addGrid(gbt.maxIter, [2, 5])\\\n",
    "  .build()\n",
    "\n",
    "# We define an evaluation metric.  This tells CrossValidator how well we are doing by comparing the true labels with predictions.\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n",
    "\n",
    "# Declare the CrossValidator, which runs model tuning for us.\n",
    "cv = CrossValidator(estimator=gbt, evaluator=evaluator, estimatorParamMaps=paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineWithCV = Pipeline(stages=[sexIndexer, ageIndexer, featureAssembler, featureIndexer, cv])\n",
    "modelWithCV = pipelineWithCV.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = modelWithCV.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(7, {0: 0.0937, 1: 0.1114, 2: 0.084, 3: 0.0685, 5: 0.3206, 6: 0.3218})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelWithCV.stages[-1].bestModel.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelWithCV.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 13.948\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"SuicidePer100k\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions2)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
